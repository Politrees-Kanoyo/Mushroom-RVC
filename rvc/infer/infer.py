import asyncio
import gc
import os

import edge_tts
import gradio as gr
import torch
import yt_dlp
from fairseq import checkpoint_utils
from pydub import AudioSegment
from scipy.io import wavfile

from rvc.infer.config import Config
from rvc.infer.pipeline import VC
from rvc.lib.algorithm.synthesizers import Synthesizer
from rvc.lib.my_utils import load_audio

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º –∏ —Ñ–∞–π–ª–∞–º (–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã)
RVC_MODELS_DIR = os.path.join(os.getcwd(), "models", "RVC_models")
OUTPUT_DIR = os.path.join(os.getcwd(), "output", "RVC_output")
DOWNLOAD_DIR = os.path.join(os.getcwd(), "output", "YT_DLP_output")
HUBERT_BASE_PATH = os.path.join(os.getcwd(), "rvc", "models", "embedders", "hubert_base.pt")

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
os.makedirs(RVC_MODELS_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = Config()


# –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.
def display_progress(percent, message, progress=gr.Progress()):
    print(message)
    progress(percent, desc=message)


# –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏.
def load_rvc_model(rvc_model):
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
    model_dir = os.path.join(RVC_MODELS_DIR, rvc_model)
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
    model_files = os.listdir(model_dir)

    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .pth
    rvc_model_path = next((os.path.join(model_dir, f) for f in model_files if f.endswith(".pth")), None)
    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .index
    rvc_index_path = next((os.path.join(model_dir, f) for f in model_files if f.endswith(".index")), None)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
    if not rvc_model_path:
        raise ValueError(
            f"\033[91m–û–®–ò–ë–ö–ê!\033[0m –ú–æ–¥–µ–ª—å {rvc_model} –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –¥–æ–ø—É—Å—Ç–∏–ª–∏ –æ—à–∏–±–∫—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∏–ª–∏ —É–∫–∞–∑–∞–ª–∏ –Ω–µ–≤–µ—Ä–Ω—É—é —Å—Å—ã–ª–∫—É –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ."
        )

    return rvc_model_path, rvc_index_path


# –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Hubert
def load_hubert(model_path):
    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([model_path], suffix="")
    hubert = models[0].to(config.device)
    hubert = hubert.float()
    hubert.eval()
    return hubert


# –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞
def get_vc(model_path):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞
    cpt = torch.load(model_path, map_location="cpu", weights_only=True)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –º–æ–¥–µ–ª–∏
    if "config" not in cpt or "weight" not in cpt:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è {model_path}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—É—é –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ RVC v2.")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    tgt_sr = cpt["config"][-1]
    cpt["config"][-3] = cpt["weight"]["emb_g.weight"].shape[0]
    pitch_guidance = cpt.get("f0", 1)
    version = cpt.get("version", "v1")
    # vocoder = cpt.get("vocoder", "HiFi-GAN") ‚Äî –Ω–∞ –±—É–¥—É—â–µ–µ
    input_dim = 768 if version == "v2" else 256

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä
    net_g = Synthesizer(*cpt["config"], use_f0=pitch_guidance, input_dim=input_dim)

    # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–π —Å–ª–æ–π
    del net_g.enc_q
    net_g.load_state_dict(cpt["weight"], strict=False)
    net_g = net_g.to(config.device).float()
    net_g.eval()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
    vc = VC(tgt_sr, config)
    return cpt, version, net_g, tgt_sr, vc


# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ —Å–≤–µ—Ä–µ–æ –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —Ñ–æ—Ä–º–∞—Ç
def convert_audio(input_audio, output_audio, output_format):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
    audio = AudioSegment.from_file(input_audio)

    # –ï—Å–ª–∏ –∞—É–¥–∏–æ –º–æ–Ω–æ, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ –≤ —Å—Ç–µ—Ä–µ–æ
    if audio.channels == 1:
        audio = audio.set_channels(2)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    audio.export(output_audio, format=output_format)


# –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º edge_tts.
async def text_to_speech(text, voice, output_path):
    communicate = edge_tts.Communicate(text=text, voice=voice)
    await communicate.save(output_path)


# –°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ URL
def download_audio_from_url(url):
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": os.path.join(DOWNLOAD_DIR, "%(title)s.%(ext)s"),
        "postprocessors": [
            {
                "key": "FFmpegExtractAudio",
                "preferredcodec": "wav",
            }
        ],
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info_dict = ydl.extract_info(url, download=True)
        file_path = ydl.prepare_filename(info_dict)
    return file_path


# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RVC
def rvc_infer(
    voice_rvc=None,
    voice_tts=None,
    input_path_link=None,
    input_text=None,
    f0_method="rmvpe",
    hop_length=128,
    pitch=0,
    index_rate=0.5,
    volume_envelope=0.25,
    protect=0.33,
    filter_radius=3,
    f0_min=50,
    f0_max=1100,
    output_format="wav",
    use_tts=False,
):
    if not voice_rvc:
        raise ValueError("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≥–æ–ª–æ—Å–∞ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")

    display_progress(0, "\n[‚öôÔ∏è] –ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
    if use_tts:
        if not input_text:
            raise ValueError("–í–≤–µ–¥–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞.")
        if not voice_tts:
            raise ValueError("–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –∏ –≥–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏.")

        display_progress(0.2, "[üéôÔ∏è] –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏...")
        input_audio = os.path.join(OUTPUT_DIR, "TTS_Voice.wav")
        asyncio.run(text_to_speech(input_text, voice_tts, input_audio))
    else:
        if not input_path_link:
            raise ValueError("–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ –∞—É–¥–∏–æ.")

        # –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ input_path_link URL-–∞–¥—Ä–µ—Å–æ–º
        if input_path_link.startswith(("http://", "https://")):
            display_progress(0.2, "[üåê] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ —Å URL...")
            input_audio = download_audio_from_url(input_path_link)
        else:
            input_audio = input_path_link
            if not os.path.exists(input_audio):
                raise ValueError(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª {input_audio}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ –Ω–µ–º—É."
                )

    base_name = os.path.splitext(os.path.basename(input_audio))[0]
    output_audio = os.path.join(OUTPUT_DIR, f"{base_name}_(Converted).{output_format}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Hubert
    hubert_model = load_hubert(HUBERT_BASE_PATH)
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å
    model_path, index_path = load_rvc_model(voice_rvc)
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞
    cpt, version, net_g, tgt_sr, vc = get_vc(model_path)
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
    audio = load_audio(input_audio, 16000)
    pitch_guidance = cpt.get("f0", 1)

    display_progress(0.5, f"[üåå] –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ ‚Äî {base_name}...")
    audio_opt = vc.pipeline(
        hubert_model,
        net_g,
        0,
        audio,
        input_audio,
        pitch,
        f0_method,
        index_path,
        index_rate,
        pitch_guidance,
        filter_radius,
        volume_envelope,
        version,
        protect,
        hop_length,
        f0_file=None,
        f0_min=f0_min,
        f0_max=f0_max,
    )
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ wav —Ñ–∞–π–ª
    wavfile.write(output_audio, tgt_sr, audio_opt)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ —Å–≤–µ—Ä–µ–æ –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —Ñ–æ—Ä–º–∞—Ç
    display_progress(0.8, "[üí´] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Å—Ç–µ—Ä–µ–æ...")
    convert_audio(output_audio, output_audio, output_format)

    display_progress(1.0, f"[‚úÖ] –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Äî {output_audio}")

    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
    del hubert_model, cpt, net_g, vc
    gc.collect()
    torch.cuda.empty_cache()

    if use_tts:
        return output_audio, input_audio
    else:
        return output_audio
