import asyncio
import gc
import os

import edge_tts
import gradio as gr
import torch
from fairseq.checkpoint_utils import load_model_ensemble_and_task
from fairseq.data.dictionary import Dictionary
from pydub import AudioSegment
from scipy.io import wavfile

from rvc.infer.config import Config
from rvc.infer.pipeline import VC
from rvc.lib.algorithm.synthesizers import Synthesizer
from rvc.lib.my_utils import load_audio

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º –∏ —Ñ–∞–π–ª–∞–º (–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã)
RVC_MODELS_DIR = os.path.join(os.getcwd(), "models", "RVC_models")
OUTPUT_DIR = os.path.join(os.getcwd(), "output", "RVC_output")
HUBERT_BASE_PATH = os.path.join(os.getcwd(), "rvc", "models", "embedders", "hubert_base.pt")

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
os.makedirs(RVC_MODELS_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = Config()


# –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.
def display_progress(percent, message, is_print, progress=gr.Progress()):
    if is_print:
        print(message)
    progress(percent, desc=message)


# –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏.
def load_rvc_model(rvc_model):
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
    model_dir = os.path.join(RVC_MODELS_DIR, rvc_model)
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
    model_files = os.listdir(model_dir)

    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .pth
    rvc_model_path = next((os.path.join(model_dir, f) for f in model_files if f.endswith(".pth")), None)
    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .index
    rvc_index_path = next((os.path.join(model_dir, f) for f in model_files if f.endswith(".index")), None)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
    if not rvc_model_path:
        raise ValueError(
            f"\033[91m–û–®–ò–ë–ö–ê!\033[0m –ú–æ–¥–µ–ª—å {rvc_model} –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –¥–æ–ø—É—Å—Ç–∏–ª–∏ –æ—à–∏–±–∫—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∏–ª–∏ —É–∫–∞–∑–∞–ª–∏ –Ω–µ–≤–µ—Ä–Ω—É—é —Å—Å—ã–ª–∫—É –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ."
        )

    return rvc_model_path, rvc_index_path


# –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Hubert
def load_hubert(model_path):
    torch.serialization.add_safe_globals([Dictionary])
    model, _, _ = load_model_ensemble_and_task([model_path], suffix="")
    hubert = model[0].to(config.device).float()
    hubert.eval()
    return hubert


# –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞
def get_vc(model_path):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞
    cpt = torch.load(model_path, map_location="cpu", weights_only=True)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –º–æ–¥–µ–ª–∏
    if "config" not in cpt or "weight" not in cpt:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è {model_path}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—É—é –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ RVC v2.")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    tgt_sr = cpt["config"][-1]
    cpt["config"][-3] = cpt["weight"]["emb_g.weight"].shape[0]

    use_f0 = cpt.get("f0", 1)
    version = cpt.get("version", "v1")
    vocoder = cpt.get("vocoder", "HiFi-GAN")
    input_dim = 768 if version == "v2" else 256

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä
    net_g = Synthesizer(*cpt["config"], use_f0=use_f0, text_enc_hidden_dim=input_dim, vocoder=vocoder)

    # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–π —Å–ª–æ–π
    del net_g.enc_q
    net_g.load_state_dict(cpt["weight"], strict=False)
    net_g = net_g.to(config.device).float()
    net_g.eval()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
    vc = VC(tgt_sr, config)
    return cpt, version, net_g, tgt_sr, vc, use_f0


# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —Ñ–æ—Ä–º–∞—Ç
def convert_audio(input_audio, output_audio, output_format):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
    audio = AudioSegment.from_file(input_audio)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    audio.export(output_audio, format=output_format)


# –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º edge_tts.
async def text_to_speech(voice, text, rate, volume, pitch, output_path):
    if not -100 <= rate <= 100:
        raise ValueError("Rate –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -100% –¥–æ +100%")
    if not -100 <= volume <= 100:
        raise ValueError("Volume –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -100% –¥–æ +100%")
    if not -100 <= pitch <= 100:
        raise ValueError("Pitch –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -100Hz –¥–æ +100Hz")

    rate = f"+{rate}%" if rate >= 0 else f"{rate}%"
    volume = f"+{volume}%" if volume >= 0 else f"{volume}%"
    pitch = f"+{pitch}Hz" if pitch >= 0 else f"{pitch}Hz"

    communicate = edge_tts.Communicate(voice=voice, text=text, rate=rate, volume=volume, pitch=pitch)
    await communicate.save(output_path)


# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RVC
def rvc_infer(
    rvc_model=None,
    input_path=None,
    f0_method="rmvpe",
    f0_min=50,
    f0_max=1100,
    rvc_pitch=0,
    protect=0.5,
    index_rate=0,
    volume_envelope=1,
    autopitch=False,
    autopitch_threshold=155.0,
    autotune=False,
    autotune_strength=1.0,
    output_format="wav",
):
    if not rvc_model:
        raise ValueError("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≥–æ–ª–æ—Å–∞ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")
    if not os.path.exists(input_path):
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª '{input_path}'. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ –Ω–µ–º—É.")

    display_progress(0, "\n[‚öôÔ∏è] –ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...", True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Hubert
    display_progress(0.1, "–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Hubert...", False)
    hubert_model = load_hubert(HUBERT_BASE_PATH)
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å
    display_progress(0.2, "–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å...", False)
    model_path, index_path = load_rvc_model(rvc_model)
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞
    display_progress(0.3, "–ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞...", False)
    cpt, version, net_g, tgt_sr, vc, use_f0 = get_vc(model_path)

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    base_name = os.path.splitext(os.path.basename(input_path))[0]
    if len(base_name) > 50:
        gr.Warning("–ò–º—è —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 50 —Å–∏–º–≤–æ–ª–æ–≤ –∏ –±—É–¥–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω–æ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.")
        base_name = "Made_in_PolGen"  # –°–º–µ–Ω–∏—Ç—å –∏–º—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –±–æ–ª–µ–µ 50 —Å–∏–º–≤–æ–ª–æ–≤
    output_path = os.path.join(OUTPUT_DIR, f"{base_name}_({rvc_model}).{output_format}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
    display_progress(0.4, "–ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª...", False)
    audio = load_audio(input_path, 16000)

    display_progress(0.5, f"[üåå] –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ ‚Äî {base_name}...", True)
    audio_opt = vc.pipeline(
        hubert_model,
        net_g,
        0,
        audio,
        0 if autopitch else rvc_pitch,
        f0_min,
        f0_max,
        f0_method,
        index_path,
        index_rate,
        use_f0,
        volume_envelope,
        version,
        protect,
        autopitch,
        autopitch_threshold,
        autotune,
        autotune_strength,
    )
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    display_progress(0.8, "[üí´] –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç...", True)
    wavfile.write(output_path, tgt_sr, audio_opt)
    convert_audio(output_path, output_path, output_format)

    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
    display_progress(0.9, "–û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å...", False)
    del hubert_model, cpt, net_g, vc
    gc.collect()
    torch.cuda.empty_cache()

    display_progress(1.0, f"[‚úÖ] –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Äî {output_path}", True)
    return gr.Audio(output_path, label=os.path.basename(output_path))


def rvc_edgetts_infer(
    # RVC
    rvc_model=None,
    f0_method="rmvpe",
    f0_min=50,
    f0_max=1100,
    rvc_pitch=0,
    protect=0.5,
    index_rate=0,
    volume_envelope=1,
    autopitch=False,
    autopitch_threshold=155.0,
    autotune=False,
    autotune_strength=1.0,
    output_format="wav",
    # EdgeTTS
    tts_voice=None,
    tts_text=None,
    tts_rate=0,
    tts_volume=0,
    tts_pitch=0,
):
    if not tts_text:
        raise ValueError("–í–≤–µ–¥–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞.")
    if not tts_voice:
        raise ValueError("–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –∏ –≥–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏.")

    display_progress(1.0, "[üéôÔ∏è] –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å...", False)
    input_path = os.path.join(OUTPUT_DIR, "TTS_Voice.wav")
    asyncio.run(text_to_speech(tts_voice, tts_text, tts_rate, tts_volume, tts_pitch, input_path))

    output_path = rvc_infer(
        rvc_model=rvc_model,
        input_path=input_path,
        f0_method=f0_method,
        f0_min=f0_min,
        f0_max=f0_max,
        rvc_pitch=rvc_pitch,
        protect=protect,
        index_rate=index_rate,
        volume_envelope=volume_envelope,
        autopitch=autopitch,
        autopitch_threshold=autopitch_threshold,
        autotune=autotune,
        autotune_strength=autotune_strength,
        output_format=output_format,
    )

    return input_path, output_path
